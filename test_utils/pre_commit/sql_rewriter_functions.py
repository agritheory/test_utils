import ast
import re
import shutil
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
import difflib
import asttokens
from test_utils.utils.sql_registry import SQLRegistry
from test_utils.utils.sql_registry.scanner import (
	is_frappe_db_sql_call,
	extract_sql_from_call,
	get_function_context,
)


def extract_unvalidated_qb(qb_equivalent: str) -> str | None:
	"""Pull out the unvalidated generated code stored inside a MANUAL comment block.

	When the registry marks a conversion as MANUAL it stashes the raw generated
	code as commented-out lines:

	    # MANUAL: Validation failed - <reason>
	    # Generated (unvalidated):
	    # result = frappe.qb.from_("Foo")...

	This function strips the ``# `` prefix and returns the runnable code, or
	``None`` if no such block is present.
	"""
	lines = qb_equivalent.split("\n")
	unvalidated: list[str] = []
	in_block = False
	for line in lines:
		if "# Generated (unvalidated):" in line:
			in_block = True
			continue
		if in_block:
			if line.startswith("# "):
				unvalidated.append(line[2:])
			elif line.startswith("#"):
				unvalidated.append(line[1:])
			else:
				# Non-comment line ends the block
				break
	return "\n".join(unvalidated) if unvalidated else None


def compile_check(content: str, file_path: Path) -> tuple[bool, str | None]:
	"""Return (ok, error_message). Uses ast.parse — no disk I/O needed."""
	try:
		ast.parse(content, filename=str(file_path))
		return True, None
	except SyntaxError as e:
		return False, f"SyntaxError at line {e.lineno}: {e.msg}"


def remove_bak(file_path: Path) -> None:
	"""Delete the .bak file that was created as a write-time safety net."""
	bak = file_path.with_suffix(f"{file_path.suffix}.bak")
	try:
		bak.unlink(missing_ok=True)
	except OSError:
		pass


def remove_pycache(file_path: Path) -> None:
	"""Remove __pycache__ .pyc entries that correspond to *file_path*.

	Only the .pyc files for this specific module are removed (e.g.
	``__pycache__/foo.cpython-310.pyc``).  If the directory becomes empty
	afterwards it is also removed.
	"""
	pycache = file_path.parent / "__pycache__"
	if not pycache.is_dir():
		return
	stem = file_path.stem
	for pyc in pycache.glob(f"{stem}.*.pyc"):
		try:
			pyc.unlink()
		except OSError:
			pass
	# Also handle the plain ``foo.pyc`` form (Python 2 / edge cases)
	plain_pyc = pycache / f"{stem}.pyc"
	if plain_pyc.exists():
		try:
			plain_pyc.unlink()
		except OSError:
			pass
	try:
		# Remove the directory itself if it is now empty
		if pycache.is_dir() and not any(pycache.iterdir()):
			pycache.rmdir()
	except OSError:
		pass


def split_qb_code(qb: str) -> tuple[list[str], list[str], str]:
	"""Split QB code into (import_lines, doctype_lines, query_expression).

	QB equivalents may contain three distinct kinds of leading lines:

	* **import_lines** — module-level imports generated by the converter
	  (``from frappe.query_builder import functions as fn``).  These should
	  be added *once* at the top of the file, not repeated for every call.

	* **doctype_lines** — DocType variable assignments that bind a table alias
	  (``q = frappe.qb.DocType("Email Queue")``).  These must be inserted as
	  separate statements *immediately before* the enclosing statement.

	* **query_expression** — the pure QB call expression, stripped of any
	  leading assignment or return prefix, ready for inline substitution.
	"""
	lines = qb.strip().splitlines()
	import_lines: list[str] = []
	doctype_lines: list[str] = []
	expr_start_idx = 0

	for i, line in enumerate(lines):
		stripped = line.strip()
		if re.match(r"^(?:import |from \S+ import )", stripped):
			import_lines.append(stripped)
			expr_start_idx = i + 1
		elif re.match(r"^\w+\s*=\s*frappe\.qb\.DocType\(", stripped):
			doctype_lines.append(stripped)
			expr_start_idx = i + 1
		elif stripped:
			expr_start_idx = i
			break

	expr_lines = lines[expr_start_idx:]
	while expr_lines and not expr_lines[0].strip():
		expr_lines = expr_lines[1:]

	expr = strip_assignment_prefix("\n".join(expr_lines))
	return import_lines, doctype_lines, expr


def ensure_imports(content: str, import_lines: list[str]) -> str:
	"""Add *import_lines* to *content* if they are not already present.

	Each line is checked with a simple substring test against the full file.
	Missing imports are inserted after the last **module-level** import
	(determined via AST to avoid matching imports inside functions).
	"""
	if not import_lines:
		return content

	# Deduplicate within the list first (preserve order), then filter against content.
	seen: dict[str, None] = {}
	for line in import_lines:
		seen[line] = None
	missing = [line for line in seen if line not in content]
	if not missing:
		return content

	# Use AST to find the last module-level import node (0-based line index).
	insert_after = 0  # default: insert at top of file
	try:
		tree = ast.parse(content)
		for node in tree.body:  # only top-level statements
			if isinstance(node, (ast.Import, ast.ImportFrom)):
				insert_after = node.end_lineno or node.lineno  # 1-based
	except SyntaxError:
		pass

	lines = content.splitlines(keepends=True)
	injection = "".join(m + "\n" for m in missing)
	lines.insert(insert_after, injection)
	return "".join(lines)


def stmt_path_from_call_path(call_path: str) -> str | None:
	"""Derive the XPath of the enclosing statement from a Call node's XPath.

	Finds the last body-list element in the path and returns the path up to
	and including the statement node that immediately follows it::

	    /Module/body/ClassDef/body/FunctionDef/body/Assign/value/Call
	    → /Module/body/ClassDef/body/FunctionDef/body/Assign
	"""
	matches = list(
		re.finditer(
			r"/(?:body|orelse|handlers|finalbody)(?:\[\d+\])?/[A-Za-z]+(?:\[\d+\])?",
			call_path,
		)
	)
	return call_path[: matches[-1].end()] if matches else None


def find_enclosing_stmt(tree: ast.AST, target: ast.AST) -> ast.AST:
	"""Return the innermost AST *statement* node that contains *target*.

	Walks up the parent chain until it finds a node that is a direct element
	of a ``body`` / ``orelse`` / ``handlers`` / ``finalbody`` list.
	"""
	parents: dict[int, ast.AST] = {}
	for node in ast.walk(tree):
		for child in ast.iter_child_nodes(node):
			parents[id(child)] = node

	_BODY_FIELDS = frozenset({"body", "orelse", "handlers", "finalbody"})
	current = target
	while id(current) in parents:
		parent = parents[id(current)]
		for field_name, field_value in ast.iter_fields(parent):
			if (
				field_name in _BODY_FIELDS
				and isinstance(field_value, list)
				and current in field_value
			):
				return current
		current = parent
	return current  # fallback


def strip_assignment_prefix(qb: str) -> str:
	"""Return just the expression from a QB equivalent string for inline substitution.

	The asttokens-based rewriter replaces only the ``frappe.db.sql(...)`` Call
	node's character span.  The surrounding Python statement (assignment, return,
	for-loop iter, bare expression, etc.) is preserved verbatim.  So we only
	want to inject the *expression* — we must strip any leading assignment or
	return that the converter wrote for standalone-statement context.

	Examples::

	    'result = frappe.qb.from_(...).run()'  → 'frappe.qb.from_(...).run()'
	    'return frappe.get_all(...)'            → 'frappe.get_all(...)'
	    'frappe.db.delete(...)'                 → 'frappe.db.delete(...)'
	    'frappe.get_all(...)'                   → 'frappe.get_all(...)'

	Multi-line QB blocks are collapsed to a single line (newlines → spaces) so
	that inline substitution does not create indentation chaos; Black is run
	afterwards to re-format.
	"""
	s = qb.strip()

	# Strip 'return <expr>' → '<expr>'
	if re.match(r"^return\s", s):
		s = re.sub(r"^return\s+", "", s, count=1)
	# Strip 'name = <expr>' or 'self.x = <expr>' (simple/dotted assignment, not ==)
	elif m := re.match(r"^[\w][\w.]*\s*=(?!=)\s*([\s\S]+)", s):
		s = m.group(1).lstrip("\n")

	# Collapse to a single line — Black will re-format.
	return " ".join(s.split())


def apply_black(content: str) -> str:
	"""Format Python source with the Black Python API (no subprocess, no temp files)."""
	try:
		import black

		return black.format_str(content, mode=black.Mode(use_tabs=True, tab_width=4))
	except Exception:
		return content


@dataclass
class FileRewriteResult:
	"""Result returned by :func:`rewrite_file_calls` — safe to pass across process boundaries."""

	file_path: str
	success_ids: list = field(default_factory=list)
	failed_ids: list = field(default_factory=list)
	compiled_ok: bool = True
	written: bool = False
	messages: list = field(default_factory=list)  # list of ('ok'|'warn'|'err', text)


def locate_call_node(
	call,
	tree: ast.AST,
	xml_tree,
	node_mappings: dict,
	atok: asttokens.ASTTokens,
) -> "ast.Call | None":
	"""Return the AST Call node for *call*, preferring the XPath pin over text match."""
	ast_path_val = getattr(call, "ast_path", None)
	if ast_path_val and xml_tree is not None:
		try:
			matches = xml_tree.xpath(ast_path_val)
			if matches:
				return node_mappings.get(matches[0])
		except Exception:
			pass

	# Fallback: SQL text + function context + occurrence index
	candidates: list[ast.Call] = []
	for node in ast.walk(tree):
		if not isinstance(node, ast.Call) or not is_frappe_db_sql_call(node):
			continue
		sql = extract_sql_from_call(node)
		if sql and sql.strip() == call.sql_query.strip():
			if get_function_context(tree, node) == call.function_context:
				candidates.append(node)
	if not candidates:
		for node in ast.walk(tree):
			if isinstance(node, ast.Call) and is_frappe_db_sql_call(node):
				sql = extract_sql_from_call(node)
				if sql and sql.strip() == call.sql_query.strip():
					candidates.append(node)
	if candidates:
		candidates.sort(key=lambda n: atok.get_text_range(n)[0])
		occ = getattr(call, "occurrence_in_function", 0) or 0
		return candidates[min(occ, len(candidates) - 1)]
	return None


def locate_enclosing_stmt_node(
	call,
	tree: ast.AST,
	xml_tree,
	node_mappings: dict,
	target: ast.AST,
) -> ast.AST:
	"""Return the innermost statement that encloses *target*, using XPath when available."""
	ast_path_val = getattr(call, "ast_path", None)
	if xml_tree is not None and ast_path_val:
		stmt_xpath = stmt_path_from_call_path(ast_path_val)
		if stmt_xpath:
			stmt_matches = xml_tree.xpath(stmt_xpath)
			if stmt_matches:
				node = node_mappings.get(stmt_matches[0])
				if node is not None:
					return node
	return find_enclosing_stmt(tree, target)


def rewrite_file_calls(
	file_path: str,
	calls: list,
	force: bool = False,
	dry_run: bool = False,
) -> FileRewriteResult:
	"""Apply all SQL rewrites for one file. Top-level so it can run in a worker process.

	Parses the AST and builds the XML tree exactly once regardless of the number
	of calls, then collects all character-range splices and applies them in a single
	right-to-left pass before formatting and writing.
	"""
	path = Path(file_path)
	msgs: list[tuple[str, str]] = []
	all_call_ids = [c.call_id for c in calls]

	content = path.read_text(encoding="utf-8")

	ok_pre, err_pre = compile_check(content, path)
	if not ok_pre:
		msgs.append(("err", f"Skipping {file_path}: does not compile — {err_pre}"))
		return FileRewriteResult(file_path, [], all_call_ids, False, False, msgs)

	try:
		tree = ast.parse(content)
	except SyntaxError as e:
		msgs.append(("err", f"Skipping {file_path}: SyntaxError — {e}"))
		return FileRewriteResult(file_path, [], all_call_ids, False, False, msgs)

	# Build XML tree once for all calls in this file.
	node_mappings: dict = {}
	xml_tree = None
	try:
		from astpath.asts import convert_to_xml

		xml_tree = convert_to_xml(tree, node_mappings=node_mappings)
	except Exception:
		pass

	atok = asttokens.ASTTokens(content, tree=tree)

	# Collect (start, end, replacement_text) for every successful locate.
	# DocType inserts are represented as (pos, pos, text) — start == end.
	splices: list[tuple[int, int, str]] = []
	success_ids: list[str] = []
	failed_ids: list[str] = []

	for call in calls:
		target = locate_call_node(call, tree, xml_tree, node_mappings, atok)
		if target is None:
			msgs.append(
				("warn", f"  Could not locate {call.call_id[:8]} in {file_path} — skipping")
			)
			failed_ids.append(call.call_id)
			continue

		call_start, call_end = atok.get_text_range(target)
		_, doctype_lines, qb_expr = split_qb_code(call.query_builder_equivalent)

		splices.append((call_start, call_end, qb_expr))

		if doctype_lines:
			stmt_node = locate_enclosing_stmt_node(call, tree, xml_tree, node_mappings, target)
			stmt_start, _ = atok.get_text_range(stmt_node)
			line_start = content.rfind("\n", 0, stmt_start) + 1
			indent = content[line_start:stmt_start]
			setup_text = "".join(indent + dl + "\n" for dl in doctype_lines)
			splices.append((line_start, line_start, setup_text))

		success_ids.append(call.call_id)

	if not success_ids:
		return FileRewriteResult(file_path, [], failed_ids, True, False, msgs)

	# Apply all splices in right-to-left order so earlier positions stay valid.
	splices.sort(key=lambda s: (s[0], s[1]), reverse=True)
	modified = content
	for start, end, replacement in splices:
		modified = modified[:start] + replacement + modified[end:]

	# Hoist imports needed by any converted call to module level.
	all_imports: list[str] = []
	for call in calls:
		if call.call_id in success_ids:
			imp, _, _ = split_qb_code(call.query_builder_equivalent)
			all_imports.extend(imp)
	modified = ensure_imports(modified, all_imports)

	formatted = apply_black(modified)

	ok, err = compile_check(formatted, path)
	if not ok and not force:
		msgs.append(("err", f"Aborting {file_path}: generated code does not compile — {err}"))
		return FileRewriteResult(file_path, [], all_call_ids, False, False, msgs)
	if not ok:
		msgs.append(
			("warn", f"--force: {file_path} does not compile ({err}); writing anyway")
		)

	if dry_run:
		msgs.append(("ok", f"DRY RUN — would modify: {file_path}"))
		return FileRewriteResult(file_path, success_ids, failed_ids, ok, False, msgs)

	backup_path = path.with_suffix(f"{path.suffix}.bak")
	shutil.copy2(path, backup_path)
	path.write_text(formatted, encoding="utf-8")
	if ok:
		remove_bak(path)
		remove_pycache(path)
		msgs.append(("ok", f"Successfully modified: {file_path}"))
	else:
		msgs.append(("warn", f"Backup kept for manual recovery: {backup_path}"))

	return FileRewriteResult(
		file_path, success_ids if (ok or force) else [], failed_ids, ok, True, msgs
	)


# ANSI color codes
class Colors:
	RED = "\033[91m"
	GREEN = "\033[92m"
	YELLOW = "\033[93m"
	BLUE = "\033[94m"
	MAGENTA = "\033[95m"
	CYAN = "\033[96m"
	WHITE = "\033[97m"
	RESET = "\033[0m"
	BOLD = "\033[1m"

	@classmethod
	def disable(cls):
		"""Disable colors for file output"""
		cls.RED = ""
		cls.GREEN = ""
		cls.YELLOW = ""
		cls.BLUE = ""
		cls.MAGENTA = ""
		cls.CYAN = ""
		cls.WHITE = ""
		cls.RESET = ""
		cls.BOLD = ""


class SQLRewriter:
	"""SQL to Query Builder rewriter functionality"""

	def __init__(self, registry_file: str = ".sql_registry.json", use_colors: bool = True):
		self.registry = SQLRegistry(registry_file)
		if not use_colors or not sys.stdout.isatty():
			# Disable colors if not in terminal or explicitly disabled
			Colors.disable()

	def list_sql_calls(self, file_path: str | None = None):
		"""List all SQL calls, optionally filtered by file"""
		calls = self.registry.data["calls"]

		if not calls:
			print(
				f"{Colors.YELLOW}No SQL calls found in registry. Run 'sql_registry scan' first.{Colors.RESET}"
			)
			return

		filtered_calls = []
		for call in calls.values():
			if file_path and not call.file_path.endswith(file_path):
				continue
			filtered_calls.append(call)

		if not filtered_calls:
			print(f"{Colors.YELLOW}No SQL calls match the specified criteria.{Colors.RESET}")
			return

		print(f"\n{Colors.BOLD}Found {len(filtered_calls)} SQL calls:{Colors.RESET}")
		print("=" * 80)

		for call in sorted(filtered_calls, key=lambda x: (x.file_path, x.line_number)):
			file_name = Path(call.file_path).name
			print(
				f"\n{Colors.CYAN}{call.call_id[:8]}{Colors.RESET}  {file_name}:{call.line_number}"
			)
			print(f"   Function: {call.function_context}")
			print(f"   Variable: {call.variable_name or 'None'}")
			print(f"   SQL: {call.sql_query[:100]}{'...' if len(call.sql_query) > 100 else ''}")

	def show_sql_details(self, call_id: str):
		"""Show detailed information about a specific SQL call"""
		matching_calls = [
			call
			for call in self.registry.data["calls"].values()
			if call.call_id.startswith(call_id)
		]

		if not matching_calls:
			print(
				f"{Colors.RED}No SQL call found with ID starting with '{call_id}'{Colors.RESET}"
			)
			return

		if len(matching_calls) > 1:
			print(
				f"{Colors.YELLOW}Multiple calls match '{call_id}'. Please be more specific:{Colors.RESET}"
			)
			for call in matching_calls:
				print(f"  {call.call_id[:12]} - {Path(call.file_path).name}:{call.line_number}")
			return

		call = matching_calls[0]

		print(f"\n{Colors.BOLD}SQL Call Details: {call.call_id}{Colors.RESET}")
		print("=" * 60)
		print(f"File: {call.file_path}")
		print(f"Line: {call.line_number}")
		print(f"Function: {call.function_context}")
		print(f"Variable: {call.variable_name or 'None'}")
		print(f"Implementation: {call.implementation_type}")
		print(f"Created: {call.created_at}")
		print(f"Updated: {call.updated_at}")

		print(f"\n{Colors.BOLD}Original SQL:{Colors.RESET}")
		print("-" * 40)
		print(call.sql_query)

		print(f"\n{Colors.BOLD}Query Builder Equivalent:{Colors.RESET}")
		print("-" * 40)
		print(call.query_builder_equivalent)

		if call.notes:
			print(f"\n{Colors.BOLD}Notes:{Colors.RESET}")
			print("-" * 40)
			print(call.notes)

	def rewrite_sql(self, call_id: str, dry_run: bool = True, force: bool = False):
		"""Rewrite a specific SQL call to Query Builder.

		*force* bypasses two guardrails:
		  1. Calls flagged ``# MANUAL:`` are normally skipped.  With *force* the
		     tool extracts any unvalidated code embedded in the MANUAL comment
		     block and uses that as the replacement — the result will likely need
		     manual cleanup but is a useful starting point.
		  2. If the generated code does not compile the write is normally aborted.
		     With *force* the file is written anyway (a ``.bak`` backup is always
		     created) and a prominent warning is printed.
		"""
		matching_calls = [
			call
			for call in self.registry.data["calls"].values()
			if call.call_id.startswith(call_id)
		]

		if not matching_calls:
			print(
				f"{Colors.RED}No SQL call found with ID starting with '{call_id}'{Colors.RESET}"
			)
			return False

		if len(matching_calls) > 1:
			print(
				f"{Colors.YELLOW}Multiple calls match '{call_id}'. Please be more specific.{Colors.RESET}"
			)
			return False

		import copy

		call = copy.copy(matching_calls[0])

		# Check if this call is flagged for manual review or has a conversion error
		if call.query_builder_equivalent and (
			"# MANUAL:" in call.query_builder_equivalent
			or "# Error" in call.query_builder_equivalent
		):
			if not force:
				print(
					f"\n{Colors.YELLOW}Skipping {call.call_id[:12]} - flagged for manual review:{Colors.RESET}"
				)
				print(f"  {call.query_builder_equivalent}")
				return False
			unvalidated = extract_unvalidated_qb(call.query_builder_equivalent)
			if not unvalidated:
				print(
					f"\n{Colors.RED}--force: no unvalidated code found for {call.call_id[:12]}; "
					f"cannot proceed{Colors.RESET}"
				)
				return False
			print(
				f"\n{Colors.YELLOW}--force: using unvalidated generated code for "
				f"{call.call_id[:12]} — manual cleanup required{Colors.RESET}"
			)
			call.query_builder_equivalent = unvalidated

		print(f"\n{Colors.BOLD}Rewriting SQL call: {call.call_id[:12]}{Colors.RESET}")
		print(f"File: {call.file_path}")
		print(f"Line: {call.line_number}")
		print(f"Variable: {call.variable_name or 'None'}")

		file_path = Path(call.file_path)
		if not file_path.exists():
			print(f"{Colors.RED}Error: File not found: {file_path}{Colors.RESET}")
			return False

		try:
			result = rewrite_file_calls(str(file_path), [call], force=force, dry_run=dry_run)

			for level, text in result.messages:
				color = {
					"ok": Colors.GREEN,
					"warn": Colors.YELLOW,
					"err": Colors.RED,
				}.get(level, "")
				print(f"{color}{text}{Colors.RESET}")

			if dry_run and result.success_ids:
				original_content = file_path.read_text(encoding="utf-8")
				print(f"\n{Colors.BOLD}DRY RUN - Changes that would be made:{Colors.RESET}")
				print("=" * 50)
				self.show_diff(
					original_content,
					apply_black(self.replace_sql_in_content(original_content, call)),
					call.line_number,
				)
				print(
					f"\n{Colors.CYAN}To apply: poetry run sql_registry rewrite {call_id[:8]} --apply{Colors.RESET}"
				)
				return True

			if result.written:
				call.implementation_type = "query_builder"
				call.notes = f"Converted by sql_rewriter on {datetime.now()}"
				self.registry.save_registry()
				return True

			return bool(result.success_ids)

		except Exception as e:
			print(f"{Colors.RED}Error during rewrite: {e}{Colors.RESET}")
			return False

	def rewrite_batch(
		self,
		call_ids: list[str],
		dry_run: bool = True,
		force: bool = False,
		workers: int = 0,
	) -> tuple[int, list[str]]:
		"""Rewrite multiple SQL calls in parallel across files.

		Calls are grouped by file.  Each file is processed by
		:func:`rewrite_file_calls` which parses the AST and builds the XPath
		tree exactly once, collects all character-range splices, applies them in
		a single right-to-left pass, runs Black via the Python API, compile-checks,
		and writes.

		Files are dispatched to a :class:`~concurrent.futures.ProcessPoolExecutor`
		(default: one worker per CPU) so that large codebases with dozens of files
		are processed in parallel.  *dry_run* skips the write step but still
		performs the full locate/replace/compile pipeline to verify correctness.

		*force* has the same semantics as in :meth:`rewrite_sql`.

		*workers* overrides the pool size (0 = ``os.cpu_count()``).

		Returns: (success_count, failed_call_ids)
		"""
		import copy

		calls_to_rewrite = []
		skipped_manual = []
		for call_id in call_ids:
			matching = [
				c for c in self.registry.data["calls"].values() if c.call_id.startswith(call_id)
			]
			if not matching:
				continue
			call = copy.copy(matching[0])
			if call.query_builder_equivalent and (
				"# MANUAL:" in call.query_builder_equivalent
				or "# Error" in call.query_builder_equivalent
			):
				if force:
					unvalidated = extract_unvalidated_qb(call.query_builder_equivalent)
					if unvalidated:
						print(
							f"\n{Colors.YELLOW}--force: using unvalidated code for "
							f"{call.call_id[:12]}{Colors.RESET}"
						)
						call.query_builder_equivalent = unvalidated
						calls_to_rewrite.append(call)
					else:
						print(
							f"\n{Colors.YELLOW}--force: no unvalidated code for "
							f"{call.call_id[:12]}; skipping{Colors.RESET}"
						)
						skipped_manual.append(call)
				else:
					skipped_manual.append(call)
				continue
			calls_to_rewrite.append(call)

		if skipped_manual:
			print(
				f"\n{Colors.YELLOW}Skipping {len(skipped_manual)} calls flagged for manual review:{Colors.RESET}"
			)
			for call in skipped_manual:
				print(f"  - {call.call_id[:12]}: {call.file_path}:{call.line_number}")

		if not calls_to_rewrite:
			return 0, list(call_ids)

		calls_by_file: dict[str, list] = {}
		for call in calls_to_rewrite:
			calls_by_file.setdefault(call.file_path, []).append(call)

		# Filter out files that don't exist before we hit the pool.
		success_count = 0
		failed_ids: list[str] = []
		valid_file_calls: dict[str, list] = {}
		for fp, fc in calls_by_file.items():
			if not Path(fp).exists():
				print(f"{Colors.RED}File not found: {fp}{Colors.RESET}")
				failed_ids.extend(c.call_id for c in fc)
			else:
				valid_file_calls[fp] = fc

		if not valid_file_calls:
			return 0, failed_ids

		n_workers = workers or None  # None → ProcessPoolExecutor default (cpu_count)
		futures_map = {}
		with ProcessPoolExecutor(max_workers=n_workers) as pool:
			for fp, fc in valid_file_calls.items():
				fut = pool.submit(rewrite_file_calls, fp, fc, force, dry_run)
				futures_map[fut] = fc

			for fut in as_completed(futures_map):
				try:
					result: FileRewriteResult = fut.result()
				except Exception as exc:
					fc = futures_map[fut]
					print(f"{Colors.RED}Worker error for {fc[0].file_path}: {exc}{Colors.RESET}")
					failed_ids.extend(c.call_id for c in fc)
					continue

				for level, text in result.messages:
					color = {"ok": Colors.GREEN, "warn": Colors.YELLOW, "err": Colors.RED}.get(
						level, ""
					)
					print(f"{color}{text}{Colors.RESET}")

				success_count += len(result.success_ids)
				failed_ids.extend(result.failed_ids)

				if result.written or (dry_run and result.success_ids):
					for call in futures_map[fut]:
						if call.call_id in result.success_ids:
							call.implementation_type = "query_builder"
							call.notes = f"Converted by sql_rewriter batch on {datetime.now()}"

		if not dry_run:
			self.registry.save_registry()

		return success_count, failed_ids

	def replace_sql_in_content(self, content: str, call) -> str:
		"""Replace a single ``frappe.db.sql(...)`` Call node inline.

		Delegates to :func:`locate_call_node` (XPath primary, SQL-text fallback)
		and :func:`locate_enclosing_stmt_node` for DocType line insertion.
		The QB expression is stripped of any leading assignment/return prefix and
		collapsed to one line; Black re-formats afterwards.
		"""
		try:
			tree = ast.parse(content)
		except SyntaxError:
			return content

		node_mappings: dict = {}
		xml_tree = None
		try:
			from astpath.asts import convert_to_xml

			xml_tree = convert_to_xml(tree, node_mappings=node_mappings)
		except Exception:
			pass

		atok = asttokens.ASTTokens(content, tree=tree)
		target = locate_call_node(call, tree, xml_tree, node_mappings, atok)

		if target is None:
			print(
				f"  Warning: could not locate SQL call '{call.call_id}' in "
				f"{call.file_path} — skipping"
			)
			return content

		call_start, call_end = atok.get_text_range(target)
		_, doctype_lines, qb_expr = split_qb_code(call.query_builder_equivalent)

		if not doctype_lines:
			return content[:call_start] + qb_expr + content[call_end:]

		stmt_node = locate_enclosing_stmt_node(call, tree, xml_tree, node_mappings, target)
		stmt_start, _ = atok.get_text_range(stmt_node)
		line_start = content.rfind("\n", 0, stmt_start) + 1
		indent = content[line_start:stmt_start]

		setup_text = "".join(indent + dl + "\n" for dl in doctype_lines)
		return (
			content[:line_start]
			+ setup_text
			+ content[line_start:call_start]
			+ qb_expr
			+ content[call_end:]
		)

	def apply_black_formatting(self, content: str) -> str:
		"""Format Python source with Black. Delegates to :func:`apply_black`."""
		result = apply_black(content)
		if result == content:
			print(
				f"{Colors.YELLOW}Warning: Black formatter not available or failed, skipping formatting{Colors.RESET}"
			)
		return result

	def show_diff(self, original: str, modified: str, around_line: int):
		"""Show a unified diff of changes near *around_line*."""
		orig_lines = original.splitlines()
		mod_lines = modified.splitlines()

		diff = list(
			difflib.unified_diff(
				orig_lines,
				mod_lines,
				fromfile="original",
				tofile="modified",
				lineterm="",
				n=3,
			)
		)

		if not diff:
			print("No changes detected.")
			return

		in_relevant_hunk = False
		hunk_start_line = 0

		for line in diff:
			if line.startswith("@@"):
				match = re.match(r"@@ -(\d+)", line)
				if match:
					hunk_start_line = int(match.group(1))
					in_relevant_hunk = abs(hunk_start_line - around_line) < 20
				if in_relevant_hunk:
					print(f"\n{Colors.CYAN}{line}{Colors.RESET}")
			elif line.startswith("+++") or line.startswith("---"):
				continue
			elif in_relevant_hunk:
				if line.startswith("+"):
					print(f"{Colors.GREEN}+ {line[1:]}{Colors.RESET}")
				elif line.startswith("-"):
					print(f"{Colors.RED}- {line[1:]}{Colors.RESET}")
				else:
					print(f"  {line}")
